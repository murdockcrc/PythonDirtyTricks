{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd057adcfd2b1133a83f066f9fdab119b47c9d5368683efbdea29e0e3fab08cedf9",
   "display_name": "Python 3.8.8 64-bit ('azureml': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'1.25.0'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import azureml.core\n",
    "azureml.data.__version__"
   ]
  },
  {
   "source": [
    "# Import packages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from azureml.core import Dataset, Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "dstore = ws.get_default_datastore()\n",
    "\n",
    "dset_name = 'weather-data-florida'"
   ]
  },
  {
   "source": [
    "# Download data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "weather_data_folder = os.path.join(os.getcwd(), 'weather-data/2019')\n",
    "os.makedirs(weather_data_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "for index in range (1, 9):\n",
    "    mount_path = os.path.join(os.getcwd(), f'weather-data/2019/0{index}')\n",
    "    os.makedirs(mount_path, exist_ok=True)\n",
    "\n",
    "    file_url = f'https://github.com/Azure/MachineLearningNotebooks/raw/master/how-to-use-azureml/work-with-data/datasets-tutorial/timeseries-datasets/weather-data/2019/0{index}/data.parquet'\n",
    "    response = http.request('GET', file_url)\n",
    "\n",
    "    # Write data to file\n",
    "    filename = f'{mount_path}/data.parquet'\n",
    "    file_ = open(filename, 'wb')\n",
    "    file_.write(response.data)\n",
    "    file_.close()\n",
    "    response.release_conn()"
   ]
  },
  {
   "source": [
    "# Upload the data to storage"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Uploading an estimated of 10 files\n",
      "Uploading weather-data/.DS_Store\n",
      "Uploaded weather-data/.DS_Store, 1 files out of an estimated total of 10\n",
      "Uploading weather-data/2019/.DS_Store\n",
      "Uploaded weather-data/2019/.DS_Store, 2 files out of an estimated total of 10\n",
      "Uploading weather-data/2019/03/data.parquet\n",
      "Uploaded weather-data/2019/03/data.parquet, 3 files out of an estimated total of 10\n",
      "Uploading weather-data/2019/04/data.parquet\n",
      "Uploaded weather-data/2019/04/data.parquet, 4 files out of an estimated total of 10\n",
      "Uploading weather-data/2019/05/data.parquet\n",
      "Uploaded weather-data/2019/05/data.parquet, 5 files out of an estimated total of 10\n",
      "Uploading weather-data/2019/02/data.parquet\n",
      "Uploaded weather-data/2019/02/data.parquet, 6 files out of an estimated total of 10\n",
      "Uploading weather-data/2019/07/data.parquet\n",
      "Uploaded weather-data/2019/07/data.parquet, 7 files out of an estimated total of 10\n",
      "Uploading weather-data/2019/08/data.parquet\n",
      "Uploaded weather-data/2019/08/data.parquet, 8 files out of an estimated total of 10\n",
      "Uploading weather-data/2019/01/data.parquet\n",
      "Uploaded weather-data/2019/01/data.parquet, 9 files out of an estimated total of 10\n",
      "Uploading weather-data/2019/06/data.parquet\n",
      "Uploaded weather-data/2019/06/data.parquet, 10 files out of an estimated total of 10\n",
      "Uploaded 10 files\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_a9c95c81b19742fcb7b8dbc899ffb3c8"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "dstore.upload('weather-data', dset_name, overwrite=True, show_progress=True)"
   ]
  },
  {
   "source": [
    "# Create and register tabular dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_path = [(dstore, dset_name + '/*/*/data.parquet')]\n",
    "dataset = Dataset.Tabular.from_parquet_files(path=datastore_path, partition_format = dset_name + '/{partition_time:yyyy/MM}/data.parquet')\n",
    "\n",
    "tsd = dataset.with_timestamp_columns(timestamp='datetime', partition_timestamp='partition_time')\n",
    "\n",
    "registered_ds = tsd.register(ws, dset_name, create_new_version=True, description='Data for Tabular Dataset with time-series trait demo.', tags={ 'type': 'TabularDataset' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue here\n",
    "# https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/work-with-data/datasets-tutorial/timeseries-datasets/tabular-timeseries-dataset-filtering.ipynb"
   ]
  }
 ]
}