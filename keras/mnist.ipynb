{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 334 ms\n"
     ]
    }
   ],
   "source": [
    "# Enable Intellisense\n",
    "%config IPCompleter.greedy=True\n",
    "%load_ext autotime\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "source_images = train_images\n",
    "source_test_images = test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.7 ms\n"
     ]
    }
   ],
   "source": [
    "# This is the training set:\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.66 ms\n"
     ]
    }
   ],
   "source": [
    "# This is the label set:\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 136 ms\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Define the optimizer, loss and monitoring\n",
    "network.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling\n",
    "\n",
    "Data is a 3-dimension array of (6000, 28, 28). Data samples are values ranging between [0, 255]. We need to transform those values to range [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 109 ms\n"
     ]
    }
   ],
   "source": [
    "# Convert 2-dimensional image into 1-dimensional array\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "\n",
    "# Normalize\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.71 ms\n"
     ]
    }
   ],
   "source": [
    "# Categorically encode the labels\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0282 - accuracy: 0.9916\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 0.0210 - accuracy: 0.9941\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0167 - accuracy: 0.9951\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0134 - accuracy: 0.9957\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0099 - accuracy: 0.9973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f89a0142710>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "Pick a random number from the test set. We will ask the network to predict it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_test = random.randint(0, 9999)\n",
    "test_number = source_test_images[index_test]\n",
    "test_image = test_images[index_test]\n",
    "plt.imshow(test_number, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.78895222e-12, 2.53457477e-09, 9.12979203e-07, 5.90924799e-07,\n",
       "       2.77318351e-04, 1.13212423e-07, 1.44565766e-11, 7.33809998e-07,\n",
       "       7.08646374e-03, 9.92633879e-01], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "network.predict(np.reshape(test_image, (1, 28 * 28)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}